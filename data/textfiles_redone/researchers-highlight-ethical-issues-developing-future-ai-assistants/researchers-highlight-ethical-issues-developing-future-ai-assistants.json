{"text": "Researchers Highlight Ethical Issues for Developing Future AI Assistants | News Center\nSkip to main navigation\nSkip to main content\nMENU\nNews Center\nMain navigation\nCalendar\nCategories\nBusiness and Economic Development\nCampus and Community\nEarth and Environment\nHealth and Medicine\nScience and Technology\nSociety and Culture\nMedia Contacts\nDaily Digest\nWhistle\nWhistle\nWhistle archives\nSocial Media\nSubscribe\nFeatured expert\nFeatures\nFeatures\nFeatures Archive\nFind an expert\nSearch\nSearch\nBreadcrumb\nHome\nResearchers Highlight Ethical Issues for Developing Future AI Assistants\nWith the design of AI systems that seek to enhance the abilities of older adults as they experience cognitive decline, a broad range of ethical issues arises.\nFacebook\nTwitter\nEmail\nNext-generation smart assistants will likely be designed to anticipate a user\u2019s wants and needs, and even assist and mediate social interactions between users and their support networks.\nJul 31, 2023\nMost people use voice assistant technologies like Alexa or Google Assistant for list making and quick weather updates. But imagine if these technologies could do much more \u2014 summarize doctor\u2019s appointments, remind someone to take their medicines, manage their schedule (knowing which events take priority), and not only read a recipe but also create reminders to shop for ingredients \u2014 without the user having to prompt it. If a smart assistant could use artificial intelligence to take away some of the cognitive load for common tasks, it could help older adults preserve their independence and autonomy.\nNext-generation smart assistants aren\u2019t on the market yet, but the research necessary to create them is underway now. This includes efforts to develop smart assistants that are proactive \u2014that is, the system could anticipate the user\u2019s wants and needs, and even assist and mediate social interactions between users and their support networks. But with the design of systems that seek to enhance the abilities of older adults as they experience cognitive decline, a broad range of ethical issues arises.\nResearchers from the NSF\nAI Institute for Collaborative Assistance and Responsive Interaction for Networked Groups (AI-CARING)\nsaw a need to outline some of these issues up front, with the hope that designers will consider them when developing the next generation of smart assistants. The team\u2019s article, \u201c Ethical Issues in Near-Future Socially Supportive Smart Assistants for Older Adults ,\u201d was published in the journal\nIEEE Transactions on Technology and Society .\n\u201cWe're trying to provide a landscape of the ethical issues designers need to take into account long before advanced smart assistant systems show up in a person\u2019s home,\u201d said\nJason Borenstein , professor of ethics and director of Graduate Research Ethics Programs in the\nSchool of Public Policy\nand the Office of Graduate and Postdoctoral Education at Georgia Tech. \u201cIf designers don't think through these issues, then a family might set a relative up with a system, go home, and trust that their relative is safe and secure when they might not be.\u201d\nAccording to the AI-CARING researchers, when a person relies on an AI system, that person becomes vulnerable to the system in unique ways. For people with age-related cognitive impairment who might use the technology for complicated forms of assistance, the stakes get even higher, with vulnerability increasing as their health declines. Systems that fail to perform correctly could put an older adult\u2019s welfare at significant risk.\n\u201cIf a system makes a mistake when you\u2019ve relied on it for something benign \u2014 like helping you choose the movie you\u2019re going to watch \u2014 that\u2019s not a big deal,\u201d said\nAlex John London , lead author of the paper and K&L Gates Professor of Ethics and Computational Technologies at Carnegie Mellon University. \u201cBut if you\u2019ve relied on it to remind you to take your medicine, and it doesn\u2019t remind you or tells you to take the wrong medicine, that would be a big problem.\u201d\nAccording to the researchers, to develop a system that truly prioritizes the user\u2019s well-being, designers should consider issues such as trust, reliance, privacy, and a person\u2019s changing cognitive abilities. They should also make sure the system supports the user\u2019s goals rather than the goals of an outside party such as a family member, or even a company that might seek to market products to the user.\nA system like this would require a nuanced and constantly evolving model of the user and their preferences, incorporating data from a variety of different sources. For a smart assistant to effectively do its job, it might need to share some of the main user\u2019s information with other entities, which can expose the user to risk.\nFor example, a user might want the physician\u2019s office to know that they would like a doctor\u2019s appointment. But depending on the person, they may not want that information shared with their children, or only with one child and not another. According to the researchers, designers should consider methods of sharing personal information that also uphold the user\u2019s ability to control it.\nOver trust and under trust of the system\u2019s abilities are also important issues to consider. Over trust occurs when people project onto a technology abilities that it doesn\u2019t have, which could put them at risk when the system fails to deliver in a way they anticipated. Under trust can be an issue as well, because if a system can help a person with an important task and the person chooses not to use the system, they also could be left without help.\n\u201cThe goal of our analysis is to point out challenges for creating truly assistive AI systems so that they can be incorporated into the design of AI from the beginning,\u201d London said. \u201cThis can also help stakeholders create benchmarks for performance that reflect these ethical requirements rather than trying to address ethical issues after the system has already been designed, developed, and tested.\u201d\nAccording to Borenstein, when smart assistants are created and introduced into homes, the primary user\u2019s well-being and goals should be the foremost concern.\n\u201cDesigners are certainly well-intended, but all of us can benefit from the exchange of ideas across disciplines, and from talking with people with different perspectives on these kinds of technologies,\u201d Borenstein said. \u201cThis is just one piece of that puzzle that can hopefully inform the design process.\u201d\nCitation : A. J. London, Y. S. Razin, J. Borenstein, M. Eslami, R. Perkins and P. Robinette, \" Ethical Issues in Near-Future Socially Supportive Smart Assistants for Older Adults ,\" in\u00a0 IEEE Transactions on Technology and Society .\nDOI : 10.1109/TTS.2023.3237124\nGeorgia Tech is bringing together the finest minds and voices to explore artificial intelligence \u2014 the opportunities, the risks, and above all the ethical and responsible stewardship of AI. To see our presenters and register to attend Avant South on Sept. 28 \u2013 29, visit\navantsouth.com .\nAdditional Images\nContact\nCatherine Barzler, Senior Research Writer/Editor\ncatherine.barzler@gatech.edu\nGeorgia Institute of Technology\nNorth Avenue Atlanta, GA 30332\n+1 404.894.2000\nCampus Map\nGeneral\nDirectory\nEmployment\nEmergency Information\nLegal\nEqual Opportunity, Nondiscrimination, and Anti-Harassment Policy\nLegal & Privacy Information\nHuman Trafficking Notice\nTitle IX/Sexual Misconduct\nHazing Public Disclosures\nAccessibility\nAccountability\nAccreditation\nReport Free Speech and Censorship Concern\n\u00a9 2024 Georgia Institute of\nTechnology\nGT LOGIN\nResources\nGeorgia Tech Resources\nOffices and Departments\nNews Center\nCampus Calendar\nSpecial Events\nGreenBuzz\nInstitute Communications\nVisitor Resources\nCampus Visits\nDirections to Campus\nVisitor Parking Information\nGT visitor Wireless Network Information\nGeorgia Tech Global Learning Center\nGeorgia Tech Hotel and Conference Center\nBarnes and Noble at Georgia Tech\nFerst Center for the Arts\nRobert C. Williams Paper Museum\nColleges, Instructional Sites and Research\nColleges\nCollege of Computing\nCollege of Design\nCollege of Engineering\nCollege of Sciences\nIvan Allen College of Liberal Arts\nScheller College of Business\nInstructional Sites\nGeorgia Tech-Europe\nGeorgia Tech-Shenzhen\nGeorgia Tech Online\nProfessional Education\nThe Language Institute\nGlobal Footprint\nGlobal Engagement\nResearch\nGeorgia Tech Research Institute\nResearch at Georgia Tech\nExecutive Vice President for Research\nStudent and Parent Resources\nStudent Resources\nApply\nBuzzPort\nBuzzcard\nCareer Center\nCommencement\nGraduate and Postdoctoral Information\nUndergraduate Information\nLibrary\nStudent Life\nStudent Entrepreneurship\nEducation Abroad\nCanvas\nParent Resources\nParent and Family Programs\nDivision of Student Life\nScholarships and Financial Aid\nEmployee, Alumni, and Other Resources\nEmployees\nAdministration and Finance\nAdvising and Teaching\nFaculty Affairs\nFaculty Hiring\nPostdoctoral Services\nHuman Resources\nStaff Council\nTechWorks\nAlumni and Foundation\nAlumni Association\nAlumni Career Services\nFoundation\nGiving Back to Tech\nOutreach\nStartup Companies\nEconomic Development\nIndustry Engagement\nInstitute Relations\nProfessional Education\n\u2713 Thanks for sharing! AddToAny More\u2026"}