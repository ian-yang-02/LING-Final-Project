{"text": "Ultra-Low Power Chips Help Make Small Robots More Capable | News Center\nSkip to main navigation\nSkip to main content\nMENU\nNews Center\nMain navigation\nCalendar\nCategories\nBusiness and Economic Development\nCampus and Community\nEarth and Environment\nHealth and Medicine\nScience and Technology\nSociety and Culture\nMedia Contacts\nDaily Digest\nWhistle\nWhistle\nWhistle archives\nSocial Media\nSubscribe\nFeatured expert\nFeatures\nFeatures\nFeatures Archive\nFind an expert\nSearch\nSearch\nBreadcrumb\nHome\nUltra-Low Power Chips Help Make Small Robots More Capable\nAn ultra-low power hybrid chip inspired by the brain could help give palm-sized robots the ability to collaborate and learn from their experiences.\nFacebook\nTwitter\nEmail\nA robotic car controlled by an ultra-low power hybrid chip is shown in an arena to demonstrate its ability to learn and collaborate with another robot. (Photo: Allison Carter, Georgia Tech)\nMar 05, 2019\n\u2014 Atlanta, GA\nAn ultra-low power hybrid chip inspired by the brain could help give palm-sized robots the ability to collaborate and learn from their experiences. Combined with new generations of low-power motors and sensors, the new application-specific integrated circuit (ASIC) \u2013 which operates on milliwatts of power \u2013 could help intelligent swarm robots operate for hours instead of minutes.\nTo conserve power, the chips use a hybrid digital-analog time-domain processor in which the pulse-width of signals encodes information. The neural network IC accommodates both model-based programming and collaborative reinforcement learning, potentially providing the small robots larger capabilities for reconnaissance, search-and-rescue and other missions.\nResearchers from the Georgia Institute of Technology demonstrated robotic cars driven by the unique ASICs at the 2019 IEEE International Solid-State Circuits Conference (ISSCC). The research was sponsored by the Defense Advanced Research Projects Agency (DARPA) and the Semiconductor Research Corporation (SRC) through the Center for Brain-inspired Computing Enabling Autonomous Intelligence (CBRIC).\n\u201cWe are trying to bring intelligence to these very small robots so they can learn about their environment and move around autonomously, without infrastructure,\u201d said\nArijit Raychowdhury , associate professor in Georgia Tech\u2019s\nSchool of Electrical and Computer Engineering . \u201cTo accomplish that, we want to bring low-power circuit concepts to these very small devices so they can make decisions on their own. There is a huge demand for very small, but capable robots that do not require infrastructure.\u201d\nThe cars demonstrated by Raychowdhury and graduate students Ningyuan Cao, Muya Chang and Anupam Golder navigate through an arena floored by rubber pads and surrounded by cardboard block walls. As they search for a target, the robots must avoid traffic cones and each other, learning from the environment as they go and continuously communicating with each other.\nThe cars use inertial and ultrasound sensors to determine their location and detect objects around them. Information from the sensors goes to the hybrid ASIC, which serves as the \u201cbrain\u201d of the vehicles. Instructions then go to a Raspberry Pi controller, which sends instructions to the electric motors.\nIn palm-sized robots, three major systems consume power: the motors and controllers used to drive and steer the wheels, the processor, and the sensing system. In the cars built by Raychowdhury\u2019s team, the low-power ASIC means that the motors consume the bulk of the power. \u201cWe have been able to push the compute power down to a level where the budget is dominated by the needs of the motors,\u201d he said.\nThe team is working with collaborators on motors that use micro-electromechanical (MEMS) technology able to operate with much less power than conventional motors.\n\u201cWe would want to build a system in which sensing power, communications and computer power, and actuation are at about the same level, on the order of hundreds of milliwatts,\u201d said Raychowdhury, who is the ON Semiconductor Associate Professor in the School of Electrical and Computer Engineering. \u201cIf we can build these palm-sized robots with efficient motors and controllers, we should be able to provide runtimes of several hours on a couple of AA batteries. We now have a good idea what kind of computing platforms we need to deliver this, but we still need the other components to catch up.\u201d\nIn time domain computing, information is carried on two different voltages, encoded in the width of the pulses. That gives the circuits the energy-efficiency advantages of analog circuits with the robustness of digital devices.\n\u201cThe size of the chip is reduced by half, and the power consumption is one-third what a traditional digital chip would need,\u201d said Raychowdhury. \u201cWe used several techniques in both logic and memory designs for reducing power consumption to the milliwatt range while meeting target performance.\u201d\nWith each pulse-width representing a different value, the system is slower than digital or analog devices, but Raychowdhury says the speed is sufficient for the small robots. (A milliwatt is a thousandth of a watt).\n\u201cFor these control systems, we don\u2019t need circuits that operate at multiple gigahertz because the devices aren\u2019t moving that quickly,\u201d he said. \u201cWe are sacrificing a little performance to get extreme power efficiencies. Even if the compute operates at 10 or 100 megahertz, that will be enough for our target applications.\u201d\nThe 65-nanometer CMOS chips accommodate both kinds of learning appropriate for a robot. The system can be programmed to follow model-based algorithms, and it can learn from its environment using a reinforcement system that encourages better and better performance over time \u2013 much like a child who learns to walk by bumping into things.\n\u201cYou start the system out with a predetermined set of weights in the neural network so the robot can start from a good place and not crash immediately or give erroneous information,\u201d Raychowdhury said. \u201cWhen you deploy it in a new location, the environment will have some structures that it will recognize and some that the system will have to learn. The system will then make decisions on its own, and it will gauge the effectiveness of each decision to optimize its motion.\u201d\nCommunication between the robots allow them to collaborate to seek a target.\n\u201cIn a collaborative environment, the robot not only needs to understand what it is doing, but also what others in the same group are doing,\u201d he said. \u201cThey will be working to maximize the total reward of the group as opposed to the reward of the individual.\u201d\nWith their ISSCC demonstration providing a proof-of-concept, the team is continuing to optimize designs and is working on a system-on-chip to integrate the computation and control circuitry.\n\u201cWe want to enable more and more functionality in these small robots,\u201d Raychowdhury added. \u201cWe have shown what is possible, and what we have done will now need to be augmented by other innovations.\u201d\nThis project was supported by the Semiconductor Research Corporation under grant JUMP CBRIC task ID 2777.006.\nCITATION : Ningyuan Cao, Muya Chang, Arijit Raychowdhury, \u201cA 65 nm 1.1-to-9.1 TOPS/W Hybrid-Digital-Mixed-Signal Computing Platform for Accelerating Model-Based and Model Free Swarm Robotics.\u201d (2019 IEEE International Solid-State Circuits Conference).\nResearch News\nGeorgia Institute of Technology\n177 North Avenue\nAtlanta, Georgia\u00a0 30332-0181\u00a0 USA\nMedia Relations Assistance : John Toon (404-894-6986) (jtoon@gatech.edu)\nWriter : John Toon\nWant to stay informed about the latest Georgia Tech research? Subscribe to our free monthly e-newsletter at \u00a0 www.rh.gatech.edu/subscribe\nAdditional Images\nContact\nJohn Toon\nResearch News\n(404) 894-6986\nEmail\njtoon@gatech.edu\nGeorgia Institute of Technology\nNorth Avenue Atlanta, GA 30332\n+1 404.894.2000\nCampus Map\nGeneral\nDirectory\nEmployment\nEmergency Information\nLegal\nEqual Opportunity, Nondiscrimination, and Anti-Harassment Policy\nLegal & Privacy Information\nHuman Trafficking Notice\nTitle IX/Sexual Misconduct\nHazing Public Disclosures\nAccessibility\nAccountability\nAccreditation\nReport Free Speech and Censorship Concern\n\u00a9 2024 Georgia Institute of\nTechnology\nGT LOGIN\nResources\nGeorgia Tech Resources\nOffices and Departments\nNews Center\nCampus Calendar\nSpecial Events\nGreenBuzz\nInstitute Communications\nVisitor Resources\nCampus Visits\nDirections to Campus\nVisitor Parking Information\nGT visitor Wireless Network Information\nGeorgia Tech Global Learning Center\nGeorgia Tech Hotel and Conference Center\nBarnes and Noble at Georgia Tech\nFerst Center for the Arts\nRobert C. Williams Paper Museum\nColleges, Instructional Sites and Research\nColleges\nCollege of Computing\nCollege of Design\nCollege of Engineering\nCollege of Sciences\nIvan Allen College of Liberal Arts\nScheller College of Business\nInstructional Sites\nGeorgia Tech-Europe\nGeorgia Tech-Shenzhen\nGeorgia Tech Online\nProfessional Education\nThe Language Institute\nGlobal Footprint\nGlobal Engagement\nResearch\nGeorgia Tech Research Institute\nResearch at Georgia Tech\nExecutive Vice President for Research\nStudent and Parent Resources\nStudent Resources\nApply\nBuzzPort\nBuzzcard\nCareer Center\nCommencement\nGraduate and Postdoctoral Information\nUndergraduate Information\nLibrary\nStudent Life\nStudent Entrepreneurship\nEducation Abroad\nCanvas\nParent Resources\nParent and Family Programs\nDivision of Student Life\nScholarships and Financial Aid\nEmployee, Alumni, and Other Resources\nEmployees\nAdministration and Finance\nAdvising and Teaching\nFaculty Affairs\nFaculty Hiring\nPostdoctoral Services\nHuman Resources\nStaff Council\nTechWorks\nAlumni and Foundation\nAlumni Association\nAlumni Career Services\nFoundation\nGiving Back to Tech\nOutreach\nStartup Companies\nEconomic Development\nIndustry Engagement\nInstitute Relations\nProfessional Education\n\u2713 Thanks for sharing! AddToAny More\u2026"}